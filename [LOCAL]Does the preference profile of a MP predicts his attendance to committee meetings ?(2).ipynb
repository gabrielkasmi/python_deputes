{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les centres d'intérêts des députés influencent-ils leur participation aux séances en commission permanente ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction ici: contexte général\n",
    "\n",
    "\n",
    "\n",
    "présenter la motivation\n",
    "\n",
    "<b> Stratégie d'idenfication </b>\n",
    " présenter la stratégie d'idenfication\n",
    " \n",
    " <b> Algorithmes </b>\n",
    " \n",
    " Présenter l'aspect plus algorithmique \n",
    " \n",
    " \n",
    "A demander : \n",
    "\n",
    "Récupérer le champ lexical\n",
    "\n",
    "\n",
    "préférences des députés \n",
    "\n",
    "\n",
    "\n",
    "jouer sur le nombre de catégories, voir le threshold de déclenchement \n",
    "\n",
    "idée: \n",
    "\n",
    "• définir des catégories\n",
    "•gradient de préférences pour le député\n",
    "•gradient de thématiques pour la séance\n",
    "•voir les paires de thématiques qui reviennent le plus souvent les unes à la suite des autres pour en déduire une proximité entre les différentes thématiques \n",
    "    - idée probabilité d'avoir un mot à la suite d'un autre \n",
    "    \n",
    "• calculer une distance thématique/préférence, voir le pouvoir prédictif de cette distance\n",
    "\n",
    "\n",
    "première étape pour les mots: créer une boucle, 1 ligne numero du député, une autre avec toutes ses interventions à la suite (sans traitement) \n",
    "filtrer pour les séances en hémicycle uniquement\n",
    "\n",
    "à partir de ça voir les mots qui sortent le plus souvent pour chacun des députés\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
       "<script>\n",
       "function repeat_indent_string(n){\n",
       "    var a = \"\" ;\n",
       "    for ( ; n > 0 ; --n)\n",
       "        a += \"    \";\n",
       "    return a;\n",
       "}\n",
       "// look up into all sections and builds an automated menu //\n",
       "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
       "    var anchors = document.getElementsByClassName(\"section\");\n",
       "    if (anchors.length == 0) {\n",
       "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
       "    }\n",
       "    var i,t;\n",
       "    var text_menu = begin;\n",
       "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
       "    var ind = \"\";\n",
       "    var memo_level = 1;\n",
       "    var href;\n",
       "    var tags = [];\n",
       "    var main_item = 0;\n",
       "    var format_open = 0;\n",
       "    for (i = 0; i <= llast; i++)\n",
       "        tags.push(\"h\" + i);\n",
       "\n",
       "    for (i = 0; i < anchors.length; i++) {\n",
       "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
       "\n",
       "        var child = null;\n",
       "        for(t = 0; t < tags.length; t++) {\n",
       "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
       "            if (r.length > 0) {\n",
       "child = r[0];\n",
       "break;\n",
       "            }\n",
       "        }\n",
       "        if (child == null) {\n",
       "            text_memo += \"null\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        if (anchors[i].hasAttribute(\"id\")) {\n",
       "            // when converted in RST\n",
       "            href = anchors[i].id;\n",
       "            text_memo += \"#1-\" + href;\n",
       "            // passer à child suivant (le chercher)\n",
       "        }\n",
       "        else if (child.hasAttribute(\"id\")) {\n",
       "            // in a notebook\n",
       "            href = child.id;\n",
       "            text_memo += \"#2-\" + href;\n",
       "        }\n",
       "        else {\n",
       "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        var title = child.textContent;\n",
       "        var level = parseInt(child.tagName.substring(1,2));\n",
       "\n",
       "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
       "\n",
       "        if ((level < lfirst) || (level > llast)) {\n",
       "            continue ;\n",
       "        }\n",
       "        if (title.endsWith('¶')) {\n",
       "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
       "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
       "        }\n",
       "        if (title.length == 0) {\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        while (level < memo_level) {\n",
       "            text_menu += end_format + \"</ul>\\n\";\n",
       "            format_open -= 1;\n",
       "            memo_level -= 1;\n",
       "        }\n",
       "        if (level == lfirst) {\n",
       "            main_item += 1;\n",
       "        }\n",
       "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
       "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
       "            continue;\n",
       "        }\n",
       "        while (level > memo_level) {\n",
       "            text_menu += \"<ul>\\n\";\n",
       "            memo_level += 1;\n",
       "        }\n",
       "        text_menu += repeat_indent_string(level-2);\n",
       "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
       "        format_open += 1;\n",
       "    }\n",
       "    while (1 < memo_level) {\n",
       "        text_menu += end_format + \"</ul>\\n\";\n",
       "        memo_level -= 1;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    text_menu += send;\n",
       "    //text_menu += \"\\n\" + text_memo;\n",
       "\n",
       "    while (format_open > 0) {\n",
       "        text_menu += end_format;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    return text_menu;\n",
       "};\n",
       "var update_menu = function() {\n",
       "    var sbegin = \"\";\n",
       "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
       "    var send = \"\";\n",
       "    var begin_format = '<li>';\n",
       "    var end_format = '</li>';\n",
       "    var keep_item = -1;\n",
       "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
       "       begin_format, end_format);\n",
       "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
       "    menu.innerHTML=text_menu;\n",
       "};\n",
       "window.setTimeout(update_menu,2000);\n",
       "            </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jyquickhelper import add_notebook_menu\n",
    "add_notebook_menu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Créer des catégories thématiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Première chose : créer les catégories thématiques (regrouper les champs lexicaux). Agreger toutes les interventions de tous les députés / prendre uniquement les séances en hémicycle et agréger pour tous les députés\n",
    "\n",
    "A la fin, avoir des mots qui permettent de classifier une thématique de séance\n",
    "faire du train/test pour voir si ça marche bien\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première chose à faire est de récupérer un fichier contenant toutes les interventions de tous les députés. On importe le fichier <TT>words_mps.txt</TT> qui contient l'ensemble des interventions en hémicycle de l'ensemble des députés de la XIVème législature. Plus précisément, la colonne 0 correspond à l'id du député dans notre base de données (qui nous sera utile plus tard pour retrouver la présence des députés en commission ainsi que leur groupe parlementaire). La colonne 1 est la concaténation brute de toutes ses interventions que l'on va ensuite nettoyer pour extraire les centres d'intérêts de chacun des députés.\n",
    "\n",
    "Nous utilisons un script autonome pour extraire les données à partir d'une base SQL (cf. annexes)\n",
    "\n",
    "<b>INférer les catégories à partir des séances ?  + extraire le tire (voir les trigrams/4grammes)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>('&lt;p&gt;Bla-bla-bla !&lt;/p&gt;',)(\"&lt;p&gt;Vous n'avez enco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>(\"&lt;p&gt;Ce n'est pas fini !&lt;/p&gt;\",)('&lt;p&gt;Lamentable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>(\"&lt;p&gt;J'ai bien entendu la position du Gouverne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>(\"&lt;p&gt;C'est vous qui le faites !&lt;/p&gt;\",)(\"&lt;p&gt;Mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>(\"&lt;p&gt;Monsieur le président, monsieur le minist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  1  ('<p>Bla-bla-bla !</p>',)(\"<p>Vous n'avez enco...\n",
       "1  2  (\"<p>Ce n'est pas fini !</p>\",)('<p>Lamentable...\n",
       "2  3  (\"<p>J'ai bien entendu la position du Gouverne...\n",
       "3  4  (\"<p>C'est vous qui le faites !</p>\",)(\"<p>Mon...\n",
       "4  5  (\"<p>Monsieur le président, monsieur le minist..."
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas \n",
    "import numpy as np\n",
    "\n",
    "#Attention à indiquer l'emplacement local du fichier words_mps.txt (accessible en local uniquement)\n",
    "\n",
    "df=pandas.read_csv('/Users/Gabriel/Desktop/words_mps2.txt', sep='\\t',header=None)\n",
    "#df=pandas.read_csv('/Users/Hugo/Documents/Cours/ENSAE/Python/python_deputes/words_mps.txt', sep='\\t',header=None,na_filter=False)\n",
    "df1 = df.values\n",
    "df2 = np.array(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "817602\n"
     ]
    }
   ],
   "source": [
    "#On va transformer le tableau des prises de parole des députés en hémicycle en liste unidimensionnelle\n",
    "#où les items 0...n correspondent aux prises de parole du premier député, n+1, ... n+k à celles du deuxième etc. \n",
    "#on nettoye au passage les chaines\n",
    "\n",
    "document=[]\n",
    "for i in range(0,648):\n",
    "    z = str(df2[i,1])\n",
    "    interventions=[]\n",
    "    z = z.replace('\"<p>',\"\")\n",
    "    z = z.replace(\"('<p>\",\"\")\n",
    "    z = z.replace(\"',)(\",\"\")\n",
    "    z = z.replace('\",)(','')\n",
    "    z = z.replace('\",)','')\n",
    "    z = z.replace(\"',)\",'')\n",
    "    z = z.replace(\"<p>\",'')\n",
    "    interventions=z.split(\"</p>\")\n",
    "    document.extend(interventions)\n",
    "\n",
    "print(len(document))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On procède ensuite à la vectorisation et au k-means pour extraire des clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " majorité\n",
      " ils\n",
      " faites\n",
      " gouvernement\n",
      " pourquoi\n",
      " compris\n",
      " plus\n",
      " ministre\n",
      " loi\n",
      " entre\n",
      " bien\n",
      " moins\n",
      " gauche\n",
      " 8230\n",
      " projet\n",
      " france\n",
      " leurs\n",
      " hollande\n",
      " donc\n",
      " parti\n",
      "Cluster 1:\n",
      " être\n",
      " banques\n",
      " autres\n",
      " loi\n",
      " activités\n",
      " plus\n",
      " monde\n",
      " bancaire\n",
      " régulation\n",
      " bancaires\n",
      " faire\n",
      " ans\n",
      " crise\n",
      " peut\n",
      " tout\n",
      " français\n",
      " matière\n",
      " peu\n",
      " comme\n",
      " pense\n",
      "Cluster 2:\n",
      " amendement\n",
      " 8211\n",
      " monsieur\n",
      " cette\n",
      " rapporteur\n",
      " retiré\n",
      " ministre\n",
      " adopté\n",
      " donc\n",
      " général\n",
      " cet\n",
      " bien\n",
      " fait\n",
      " 8230\n",
      " ni\n",
      " plus\n",
      " question\n",
      " également\n",
      " rapport\n",
      " commission\n",
      "Cluster 3:\n",
      " cela\n",
      " non\n",
      " plus\n",
      " jamais\n",
      " logements\n",
      " paris\n",
      " totalement\n",
      " sociaux\n",
      " logement\n",
      " bien\n",
      " quoi\n",
      " tout\n",
      " monsieur\n",
      " très\n",
      " rien\n",
      " cet\n",
      " aussi\n",
      " fait\n",
      " amendements\n",
      " bancs\n",
      "Cluster 4:\n",
      " madame\n",
      " rapporteure\n",
      " ministre\n",
      " présidente\n",
      " fait\n",
      " effectivement\n",
      " comme\n",
      " mme\n",
      " franchement\n",
      " collègues\n",
      " amendements\n",
      " amendement\n",
      " revenu\n",
      " contraire\n",
      " groupe\n",
      " bancs\n",
      " si\n",
      " monsieur\n",
      " france\n",
      " lepetit\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import nltk\n",
    "\n",
    "minidoc=document[:1000]\n",
    "\n",
    "stpwrd = stopwords.words('french')\n",
    "stpwrd.append('les')\n",
    "vectorizer = TfidfVectorizer(stop_words=stpwrd)\n",
    "X = vectorizer.fit_transform(minidoc)\n",
    "\n",
    "#NOMBRE DE CLUSTERS: arbitraire au début\n",
    "true_k = 10\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "#On a les clusters \n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k-5):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :20]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'order_centroid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6b14d262cce5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder_centroid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'order_centroid' is not defined"
     ]
    }
   ],
   "source": [
    "print(type(order_centroid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problème: sélection du nombre de clusters, on va devoir appliquer différentes méthodes et choisir le bon nombre\n",
    "    de clusters\n",
    "    \n",
    "Can, F.; Ozkarahan, E. A. (1990). \"Concepts and effectiveness of the cover-coefficient-based clustering methodology for text databases\". ACM Transactions on Database Systems. 15 (4): 483. doi:10.1145/99935.99938. especially see Section 2.7.    \n",
    "\n",
    "http://www.xavierdupre.fr/app/mlstatpy/helpsphinx/c_clus/kmeans.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choisir le nombre de clusters optimaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Créer un profil de préférence à chaque député"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a un espace de dimension k, l'idée va être d'attribuer un nuplet de coordonnées au député dans cet espace. ça nous permet de le situer dans l'espace des thématiques \n",
    "\n",
    "tout va sommer à 1, donc voir pour enlever un cluster éventuellement (si c'est bien fait, le cluster des salamaleks)\n",
    "\n",
    "side: grâce aux informations sur le député, on peut avoir la localisation en fonction de l'âge, de l'obédience politique, du sexe, de l'expérience, etc\n",
    "\n",
    "ces coordonnées définissent le profil de préférence du député"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribuer une thématique aux séances en commission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebelotte mais pour les séances en commission, très similaire aux députés (cf. script autonome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>(\"&lt;p&gt;Commission du développement durable et de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>(\"&lt;p&gt;COMMISSION DES AFFAIRES CULTURELLES ET DE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>(\"&lt;p&gt;La Commission des affaires économiques s'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>(\"&lt;p&gt;La Commission a procédé, sous la présiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>(\"&lt;p&gt;COMMISSION DES AFFAIRES SOCIALES&lt;/p&gt;&lt;p&gt;Je...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  3  (\"<p>Commission du développement durable et de...\n",
       "1  4  (\"<p>COMMISSION DES AFFAIRES CULTURELLES ET DE...\n",
       "2  5  (\"<p>La Commission des affaires économiques s'...\n",
       "3  6  (\"<p>La Commission a procédé, sous la présiden...\n",
       "4  7  (\"<p>COMMISSION DES AFFAIRES SOCIALES</p><p>Je..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "#Attention à indiquer l'emplacement local du fichier words_meetings.txt (accessible en local uniquement)\n",
    "\n",
    "df=pandas.read_csv('/Users/Gabriel/Desktop/words_meetings.txt', sep='\\t',header=None)\n",
    "#df=pandas.read_csv('/Users/Hugo/Documents/Cours/ENSAE/Python/python_deputes/words_meetings.txt', sep='\\t',header=None)\n",
    "df.head()\n",
    "df3 = df.values\n",
    "df4 = np.array(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Le problème ici est d'inférer à partir des mots qui ont été prononcés des thématiques en fonction des clusters identifiés pour les députés. Les séances en hémicycle étant pour l'essentiel le prolongement des séances en commission, les clusters devraient être appropriés (restriction aux séances en hémicycle \"législatives\" pour supprimer les questions au gouvernement qui n'ont pas grand chose à voir) \n",
    "\n",
    "Pour chaque liste, créer un gradient de proximité avec les n clusters identifiés \n",
    "chaque intervention est classée dans un des clusters\n",
    "\n",
    "on fait le ratio et celui qui arrive en premier devient la thématique de la séance\n",
    "\n",
    "\n",
    "a la fin, on a un vecteur kx2 où k est le nombre de séances et pour chaque séance on a l'id et le thème (numéro du cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voir comment la proximité thématique prédit la participation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utiliser les données de présence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a une matrice qui a $ \\sum_{i=1}^n m_i$ lignes où $m_i$ désigne le nombre de séances auxquelles aurait du assister le député $i$ compte tenu de sa commission assignée et de l'intervalle de son mandat (au moins rien, au plus une législature). La première colonne correspond au numéro du député (répété $m$ fois), la seconde au numéro de la séance (unique) et la troisième indique si le député était présent (1) ou non (0).\n",
    "\n",
    "L'idée est dans un premier temps de calculer pour tous les couples (députés,séance) la distance entre le thème de la séance et les préférences du député\n",
    "\n",
    "Ensuite une fois qu'on aura la distance l'inclure en variable indépendante et voir son pouvoir prédictif sur la présence/participation en commission. \n",
    "\n",
    "Problèmes: interprétation de la distance ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle s'écrit comme suit : \n",
    "$$\n",
    "pres_{it}=\\beta_0+\\beta_1 dist_{it}+\\beta_X\\textbf{X}+\\varepsilon_{it}\n",
    "$$\n",
    "\n",
    "Où pres=0,1 indique si le député était présent ou non et dist est la distance (euclidienne pour commencer) entre le profil thématique de la séance et le profil de préférences du député et X un set de contrôles\n",
    "\n",
    "voir où mettre le prédictif là dedans, voir s'il faut le mettre éventuellement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bibliographie\n",
    "\n",
    "\n",
    "<span>&#8226;</span> Benjamin Monnery & Maxime Le Bihan, 2018. \"Can Public and Private Sanctions Discipline Politicians? Evidence from the French Parliament,\" EconomiX Working Papers 2018-21, University of Paris Nanterre, EconomiX.\n",
    "\n",
    "<span>&#8226;</span> Wu, A. H. (2017). Gender stereotyping in academia: Evidence from economics job market rumors forum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
